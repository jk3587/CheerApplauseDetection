{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "import pandas as pd\n",
    "#from keras_tqdm import TQDMNotebookCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def data_generator(batch_size, tfrecord, start_frac=0, end_frac=1):\n",
    "    '''\n",
    "    Shuffles the Audioset training data and returns a generator of training data and boolean laughter labels\n",
    "    batch_size: batch size for each set of training data and labels\n",
    "    tfrecord: filestring of the tfrecord file to train on\n",
    "    start_frac: the starting point of the data set to use, as a fraction of total record length (used for CV)\n",
    "    end_frac: the ending point of the data set to use, as a fraction of total record length (used for CV)\n",
    "    '''\n",
    "    max_len=10\n",
    "    records = list(tf.compat.v1.python_io.tf_record_iterator(tfrecord))\n",
    "    records = records[int(start_frac*len(records)):int(end_frac*len(records))]\n",
    "    rec_len = len(records)\n",
    "    shuffle = np.random.permutation(range(rec_len))\n",
    "    num_batches = rec_len//batch_size - 1\n",
    "    j = 0\n",
    "\n",
    "    laugh_labels = [66, 67] # changed to labels for cheer and applause\n",
    "    while True:\n",
    "        X = []\n",
    "        y = []\n",
    "        for idx in shuffle[j*batch_size:(j+1)*batch_size]:\n",
    "            example = records[idx]\n",
    "            tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "            example_label = list(np.asarray(tf_seq_example.context.feature['labels'].int64_list.value))\n",
    "            laugh_bin = any((True for x in example_label if x in laugh_labels))\n",
    "            y.append(laugh_bin)\n",
    "\n",
    "            n_frames = len(tf_seq_example.feature_lists.feature_list['audio_embedding'].feature)\n",
    "            audio_frame = []\n",
    "            for i in range(n_frames):\n",
    "                audio_frame.append(np.frombuffer(tf_seq_example.feature_lists.feature_list['audio_embedding'].\n",
    "                                                         feature[i].bytes_list.value[0],np.uint8).astype(np.float32))\n",
    "            pad = [np.zeros([128], np.float32) for i in range(max_len-n_frames)]\n",
    "            audio_frame += pad\n",
    "            X.append(audio_frame)\n",
    "\n",
    "        j += 1\n",
    "        if j >= num_batches:\n",
    "            shuffle = np.random.permutation(range(rec_len))\n",
    "            j = 0\n",
    "\n",
    "        X = np.array(X)\n",
    "        yield X, np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "lr_model = Sequential()\n",
    "#lr_model.add(Dropout(0.2))\n",
    "lr_model.add(Flatten())\n",
    "lr_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "lr_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 13.2153 - accuracy: 0.6958 - val_loss: 7.8218 - val_accuracy: 0.8462\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 2s 20ms/step - loss: 0.2709 - accuracy: 0.9882 - val_loss: 8.0450 - val_accuracy: 0.8462\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 2.9005e-07 - accuracy: 1.0000 - val_loss: 7.9487 - val_accuracy: 0.8462\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.3853e-07 - accuracy: 1.0000 - val_loss: 7.9400 - val_accuracy: 0.8462\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.1343e-07 - accuracy: 1.0000 - val_loss: 7.9311 - val_accuracy: 0.8462\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 1.9559e-07 - accuracy: 1.0000 - val_loss: 7.9219 - val_accuracy: 0.8462\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.7322e-07 - accuracy: 1.0000 - val_loss: 7.9130 - val_accuracy: 0.8462\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.5360e-07 - accuracy: 1.0000 - val_loss: 7.9041 - val_accuracy: 0.8846\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.5139e-07 - accuracy: 1.0000 - val_loss: 7.8952 - val_accuracy: 0.8846\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.3350e-07 - accuracy: 1.0000 - val_loss: 7.8861 - val_accuracy: 0.8846\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 1.3204e-07 - accuracy: 1.0000 - val_loss: 7.8770 - val_accuracy: 0.8846\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.1345e-07 - accuracy: 1.0000 - val_loss: 7.8684 - val_accuracy: 0.8846\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 9.5193e-08 - accuracy: 1.0000 - val_loss: 7.8603 - val_accuracy: 0.8846\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 9.0586e-08 - accuracy: 1.0000 - val_loss: 7.8527 - val_accuracy: 0.8846\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 7.7125e-08 - accuracy: 1.0000 - val_loss: 7.8455 - val_accuracy: 0.8846\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 8.7773e-08 - accuracy: 1.0000 - val_loss: 7.8372 - val_accuracy: 0.8846\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 7.6387e-08 - accuracy: 1.0000 - val_loss: 7.8295 - val_accuracy: 0.8846\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 8.1571e-08 - accuracy: 1.0000 - val_loss: 7.8209 - val_accuracy: 0.8846\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 6.8989e-08 - accuracy: 1.0000 - val_loss: 7.8130 - val_accuracy: 0.8846\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 6.0365e-08 - accuracy: 1.0000 - val_loss: 7.8058 - val_accuracy: 0.8846\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 5.4833e-08 - accuracy: 1.0000 - val_loss: 7.7991 - val_accuracy: 0.8846\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 4.7816e-08 - accuracy: 1.0000 - val_loss: 7.7926 - val_accuracy: 0.8846\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 4.1547e-08 - accuracy: 1.0000 - val_loss: 7.7868 - val_accuracy: 0.8846\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 4.9559e-08 - accuracy: 1.0000 - val_loss: 7.7800 - val_accuracy: 0.8846\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 4.0592e-08 - accuracy: 1.0000 - val_loss: 7.7737 - val_accuracy: 0.8846\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 3.7583e-08 - accuracy: 1.0000 - val_loss: 7.7678 - val_accuracy: 0.8846\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 3.7837e-08 - accuracy: 1.0000 - val_loss: 7.7618 - val_accuracy: 0.8846\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 3.1704e-08 - accuracy: 1.0000 - val_loss: 7.7562 - val_accuracy: 0.8846\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.9821e-08 - accuracy: 1.0000 - val_loss: 7.7510 - val_accuracy: 0.8846\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.8063e-08 - accuracy: 1.0000 - val_loss: 7.7458 - val_accuracy: 0.8846\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 3.0982e-08 - accuracy: 1.0000 - val_loss: 7.7397 - val_accuracy: 0.8846\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.6749e-08 - accuracy: 1.0000 - val_loss: 7.7343 - val_accuracy: 0.8846\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 2.4701e-08 - accuracy: 1.0000 - val_loss: 7.7290 - val_accuracy: 0.8846\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.2600e-08 - accuracy: 1.0000 - val_loss: 7.7241 - val_accuracy: 0.8846\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.5753e-08 - accuracy: 1.0000 - val_loss: 7.7181 - val_accuracy: 0.8846\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.1120e-08 - accuracy: 1.0000 - val_loss: 7.7129 - val_accuracy: 0.8846\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.0643e-08 - accuracy: 1.0000 - val_loss: 7.7077 - val_accuracy: 0.8846\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.8135e-08 - accuracy: 1.0000 - val_loss: 7.7029 - val_accuracy: 0.8846\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.0873e-08 - accuracy: 1.0000 - val_loss: 7.6971 - val_accuracy: 0.8846\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.7353e-08 - accuracy: 1.0000 - val_loss: 7.6920 - val_accuracy: 0.8846\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.6048e-08 - accuracy: 1.0000 - val_loss: 7.6871 - val_accuracy: 0.8846\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 1.6129e-08 - accuracy: 1.0000 - val_loss: 7.6822 - val_accuracy: 0.8846\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 1.4481e-08 - accuracy: 1.0000 - val_loss: 7.6773 - val_accuracy: 0.8846\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 1.4019e-08 - accuracy: 1.0000 - val_loss: 7.6726 - val_accuracy: 0.8846\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.2750e-08 - accuracy: 1.0000 - val_loss: 7.6681 - val_accuracy: 0.8846\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.2985e-08 - accuracy: 1.0000 - val_loss: 7.6634 - val_accuracy: 0.8846\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 1.2967e-08 - accuracy: 1.0000 - val_loss: 7.6582 - val_accuracy: 0.8846\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.1684e-08 - accuracy: 1.0000 - val_loss: 7.6535 - val_accuracy: 0.8846\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 1.0758e-08 - accuracy: 1.0000 - val_loss: 7.6489 - val_accuracy: 0.8846\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 9.7511e-09 - accuracy: 1.0000 - val_loss: 7.6447 - val_accuracy: 0.8846\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 9.8804e-09 - accuracy: 1.0000 - val_loss: 7.6402 - val_accuracy: 0.8846\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 8.2526e-09 - accuracy: 1.0000 - val_loss: 7.6361 - val_accuracy: 0.8846\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 9.7756e-09 - accuracy: 1.0000 - val_loss: 7.6314 - val_accuracy: 0.8846\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 7.4771e-09 - accuracy: 1.0000 - val_loss: 7.6274 - val_accuracy: 0.8846\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 8.1105e-09 - accuracy: 1.0000 - val_loss: 7.6230 - val_accuracy: 0.8846\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 7.9780e-09 - accuracy: 1.0000 - val_loss: 7.6185 - val_accuracy: 0.8846\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 7.0805e-09 - accuracy: 1.0000 - val_loss: 7.6141 - val_accuracy: 0.8846\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 7.4145e-09 - accuracy: 1.0000 - val_loss: 7.6095 - val_accuracy: 0.8846\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 5.7456e-09 - accuracy: 1.0000 - val_loss: 7.6058 - val_accuracy: 0.8846\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 5.8765e-09 - accuracy: 1.0000 - val_loss: 7.6018 - val_accuracy: 0.8846\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 6.3736e-09 - accuracy: 1.0000 - val_loss: 7.5973 - val_accuracy: 0.8846\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 5.9642e-09 - accuracy: 1.0000 - val_loss: 7.5929 - val_accuracy: 0.8846\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 5.6028e-09 - accuracy: 1.0000 - val_loss: 7.5883 - val_accuracy: 0.8846\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 4.9275e-09 - accuracy: 1.0000 - val_loss: 7.5845 - val_accuracy: 0.8846\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 4.9487e-09 - accuracy: 1.0000 - val_loss: 7.5804 - val_accuracy: 0.8846\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 5.1637e-09 - accuracy: 1.0000 - val_loss: 7.5759 - val_accuracy: 0.8846\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 4.7624e-09 - accuracy: 1.0000 - val_loss: 7.5714 - val_accuracy: 0.8846\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 4.6526e-09 - accuracy: 1.0000 - val_loss: 7.5670 - val_accuracy: 0.8846\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 4.5446e-09 - accuracy: 1.0000 - val_loss: 7.5623 - val_accuracy: 0.8846\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 3.5820e-09 - accuracy: 1.0000 - val_loss: 7.5586 - val_accuracy: 0.8846\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 3.6666e-09 - accuracy: 1.0000 - val_loss: 7.5547 - val_accuracy: 0.8846\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 3.3030e-09 - accuracy: 1.0000 - val_loss: 7.5510 - val_accuracy: 0.8846\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 3.1318e-09 - accuracy: 1.0000 - val_loss: 7.5471 - val_accuracy: 0.8846\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 3.3789e-09 - accuracy: 1.0000 - val_loss: 7.5429 - val_accuracy: 0.8846\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 3.6186e-09 - accuracy: 1.0000 - val_loss: 7.5382 - val_accuracy: 0.8846\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.8916e-09 - accuracy: 1.0000 - val_loss: 7.5344 - val_accuracy: 0.8846\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 3.0868e-09 - accuracy: 1.0000 - val_loss: 7.5299 - val_accuracy: 0.8846\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.6506e-09 - accuracy: 1.0000 - val_loss: 7.5260 - val_accuracy: 0.8846\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.5342e-09 - accuracy: 1.0000 - val_loss: 7.5221 - val_accuracy: 0.8846\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.5516e-09 - accuracy: 1.0000 - val_loss: 7.5180 - val_accuracy: 0.8846\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.2217e-09 - accuracy: 1.0000 - val_loss: 7.5142 - val_accuracy: 0.8846\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.4242e-09 - accuracy: 1.0000 - val_loss: 7.5100 - val_accuracy: 0.8846\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.2409e-09 - accuracy: 1.0000 - val_loss: 7.5058 - val_accuracy: 0.8846\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 2.1141e-09 - accuracy: 1.0000 - val_loss: 7.5018 - val_accuracy: 0.8846\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 2.0144e-09 - accuracy: 1.0000 - val_loss: 7.4976 - val_accuracy: 0.8846\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.8412e-09 - accuracy: 1.0000 - val_loss: 7.4938 - val_accuracy: 0.8846\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.8784e-09 - accuracy: 1.0000 - val_loss: 7.4898 - val_accuracy: 0.8846\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.8311e-09 - accuracy: 1.0000 - val_loss: 7.4857 - val_accuracy: 0.8846\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.5931e-09 - accuracy: 1.0000 - val_loss: 7.4818 - val_accuracy: 0.8846\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.6377e-09 - accuracy: 1.0000 - val_loss: 7.4777 - val_accuracy: 0.8846\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.5284e-09 - accuracy: 1.0000 - val_loss: 7.4738 - val_accuracy: 0.8846\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 2s 21ms/step - loss: 1.2963e-09 - accuracy: 1.0000 - val_loss: 7.4703 - val_accuracy: 0.8846\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.3360e-09 - accuracy: 1.0000 - val_loss: 7.4664 - val_accuracy: 0.8846\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 1.3778e-09 - accuracy: 1.0000 - val_loss: 7.4625 - val_accuracy: 0.8846\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 1.2323e-09 - accuracy: 1.0000 - val_loss: 7.4587 - val_accuracy: 0.8846\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 1.3408e-09 - accuracy: 1.0000 - val_loss: 7.4544 - val_accuracy: 0.8846\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 1.1157e-09 - accuracy: 1.0000 - val_loss: 7.4505 - val_accuracy: 0.8846\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 2s 23ms/step - loss: 1.1694e-09 - accuracy: 1.0000 - val_loss: 7.4464 - val_accuracy: 0.8846\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.0888e-09 - accuracy: 1.0000 - val_loss: 7.4425 - val_accuracy: 0.8846\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 2s 22ms/step - loss: 1.1349e-09 - accuracy: 1.0000 - val_loss: 7.4381 - val_accuracy: 0.8846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f82b87a89b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=128\n",
    "\n",
    "CV_frac = 0.1\n",
    "train_gen = data_generator(batch_size,'bal_laugh_speech_subset.tfrecord', 0, 1-CV_frac)\n",
    "val_gen = data_generator(128,'bal_laugh_speech_subset.tfrecord', 1-CV_frac, 1)\n",
    "\n",
    "rec_len = 12657 # find # of records in 'bal_laugh_speech_subset.tfrecord'\n",
    "lr_model.fit_generator(train_gen,steps_per_epoch=int(rec_len*(1-CV_frac))//batch_size, epochs=100,\n",
    "                       validation_data=val_gen, validation_steps=int(rec_len*CV_frac)//128,\n",
    "                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f82745b9ba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr_model.history.history['accuracy'], label='train_acc')\n",
    "plt.plot(lr_model.history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.save('../Models/cheer_applause_LR_100Epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm3_model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-alpha",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
